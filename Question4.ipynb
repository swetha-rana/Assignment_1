{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyObIx9FjxwFsipqCMrzEE6f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8bdfa1f3b8d24c17b66bbb947e4bb430": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9ad27f2ba50d45918c16f0b7f4b70097",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_107b3aaf1ec44f0381200eb9b712edb7",
              "IPY_MODEL_54d6925d55c2403d9ac09518d214d9c4"
            ]
          }
        },
        "9ad27f2ba50d45918c16f0b7f4b70097": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "107b3aaf1ec44f0381200eb9b712edb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_8e73388ad0994f349669ab3782342915",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f2d98b8a5df245f0b41af4f3e11269a7"
          }
        },
        "54d6925d55c2403d9ac09518d214d9c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ca0e8a63093346b8a6a82a24a3eeef9e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c0c23169de024073a108ded22d10036f"
          }
        },
        "8e73388ad0994f349669ab3782342915": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f2d98b8a5df245f0b41af4f3e11269a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ca0e8a63093346b8a6a82a24a3eeef9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c0c23169de024073a108ded22d10036f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swetha-rana/Assignment_1/blob/main/Question4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DhnKzTaVgKRx",
        "outputId": "803fc8ed-aa2e-4785-9603-b749a0ff6f9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f6a8c458550>> (for pre_run_cell):\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36m_resume_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"resuming backend\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_jupyter_teardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mpublish_resume\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpublish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0mresume\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResumeRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/interface/interface_shared.py\u001b[0m in \u001b[0;36m_publish_resume\u001b[0;34m(self, resume)\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResumeRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRunRecord\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/interface/interface_queue.py\u001b[0m in \u001b[0;36m_publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pb.Record\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_check\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The wandb backend process has shutdown\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: The wandb backend process has shutdown"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.12.10)\n",
            "Requirement already satisfied: yaspin>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.8)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.5.6)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.27)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.10.0.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n",
            "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f6a8c458550>> (for post_run_cell):\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36m_pause_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    302\u001b[0m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"saved code: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_resume_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mpublish_pause\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    540\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpublish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0mpause\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauseRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/interface/interface_shared.py\u001b[0m in \u001b[0;36m_publish_pause\u001b[0;34m(self, pause)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpause\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauseRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResumeRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/interface/interface_queue.py\u001b[0m in \u001b[0;36m_publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pb.Record\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_check\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The wandb backend process has shutdown\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: The wandb backend process has shutdown"
          ]
        }
      ],
      "source": [
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.init(project=\"Assignment-1\", entity=\"swe-rana\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249,
          "referenced_widgets": [
            "8bdfa1f3b8d24c17b66bbb947e4bb430",
            "9ad27f2ba50d45918c16f0b7f4b70097",
            "107b3aaf1ec44f0381200eb9b712edb7",
            "54d6925d55c2403d9ac09518d214d9c4",
            "8e73388ad0994f349669ab3782342915",
            "f2d98b8a5df245f0b41af4f3e11269a7",
            "ca0e8a63093346b8a6a82a24a3eeef9e",
            "c0c23169de024073a108ded22d10036f"
          ]
        },
        "id": "FmouXlF5gt-S",
        "outputId": "98c2a6c9-e506-48e3-aeb8-f107b8244bb3"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Finishing last run (ID:y0kv8taq) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 1393... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8bdfa1f3b8d24c17b66bbb947e4bb430",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)â€¦"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
              "</div><div class=\"wandb-col\">\n",
              "</div></div>\n",
              "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
              "<br/>Synced <strong style=\"color:#cdcd00\">atomic-sweep-6</strong>: <a href=\"https://wandb.ai/swe-rana/Assignment-1/runs/y0kv8taq\" target=\"_blank\">https://wandb.ai/swe-rana/Assignment-1/runs/y0kv8taq</a><br/>\n",
              "Find logs at: <code>./wandb/run-20220225_114927-y0kv8taq/logs</code><br/>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Successfully finished last run (ID:y0kv8taq). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    Syncing run <strong><a href=\"https://wandb.ai/swe-rana/Assignment-1/runs/y0kv8taq\" target=\"_blank\">atomic-sweep-6</a></strong> to <a href=\"https://wandb.ai/swe-rana/Assignment-1\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
              "Sweep page: <a href=\"https://wandb.ai/swe-rana/Assignment-1/sweeps/tkun9brv\" target=\"_blank\">https://wandb.ai/swe-rana/Assignment-1/sweeps/tkun9brv</a><br/>\n",
              "\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f6a83ce4c50>"
            ],
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/swe-rana/Assignment-1/runs/y0kv8taq?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "(X_train,y_train),(X_test,y_test) = fashion_mnist.load_data()\n",
        "label0=[]\n",
        "label1=[]\n",
        "label2=[]\n",
        "label3=[]\n",
        "label4=[]\n",
        "label5=[]\n",
        "label6=[]\n",
        "label7=[]\n",
        "label8=[]\n",
        "label9=[]\n",
        "for i in range(len(y_train)):\n",
        "    if (y_train[i]==0):\n",
        "        label0.append(i)\n",
        "    if (y_train[i]==1):\n",
        "        label1.append(i)\n",
        "    if (y_train[i]==2):\n",
        "        label2.append(i)\n",
        "    if (y_train[i]==3):\n",
        "        label3.append(i)\n",
        "    if (y_train[i]==4):\n",
        "        label4.append(i)\n",
        "    if (y_train[i]==5):\n",
        "        label5.append(i)\n",
        "    if (y_train[i]==6):\n",
        "        label6.append(i)\n",
        "    if (y_train[i]==7):\n",
        "        label7.append(i)\n",
        "    if (y_train[i]==8):\n",
        "        label8.append(i)\n",
        "    if (y_train[i]==9):\n",
        "        label9.append(i)\n",
        "Class_names=(label0,label1,label2,label3,label4,label5,label6,label7,label8,label9)    \n",
        "data = (\"T-shirt/top\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankle boot\")\n",
        "rows=2\n",
        "columns =5\n",
        "fig = plt.figure(figsize=(10, 7))\n",
        "for i,j in zip(range(1, columns*rows +1),range(0,10)):\n",
        "        num = random.choice(Class_names[j])\n",
        "        #wandb.log({\"images\": [wandb.Image(X_train[num],caption=data[j])]})\n",
        "        fig.add_subplot(rows, columns, i)\n",
        "        plt.imshow(X_train[num],cmap =\"gray\")\n",
        "        plt.axis('off')\n",
        "        plt.title(data[j])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "UBGY9t2ehGvq",
        "outputId": "3c4c2d6c-b06f-404a-89f8-c7a8879a7746"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 10 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import exp\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "(t_train_x_orig,t_train_y),(test_x_orig,test_y)= fashion_mnist.load_data()\n",
        "\n",
        "train_x_orig,x_val,train_y,y_val=train_test_split(t_train_x_orig,t_train_y,test_size=0.1,random_state = 43)\n",
        "\n",
        "m_train = train_x_orig.shape[0]\n",
        "num_px = train_x_orig.shape[1]\n",
        "m_test = test_x_orig.shape[0]\n",
        "train_y = train_y.reshape(1, len(train_y))\n",
        "test_y = test_y.reshape(1, len(test_y))\n",
        "y_val = y_val.reshape(1, len(y_val))\n",
        "train_x_flatten = train_x_orig.reshape(train_x_orig.shape[0], -1).T\n",
        "x_val_flatten = x_val.reshape(x_val.shape[0],-1).T\n",
        "test_x_flatten = test_x_orig.reshape(test_x_orig.shape[0], -1).T\n",
        "no_of_class=10\n",
        "\n",
        "train_x = train_x_flatten/255\n",
        "test_x = test_x_flatten/255\n",
        "x_val = x_val_flatten/255\n",
        "#layers_dims = [len(train_x),256,128,no_of_class]\n",
        "onehot_encoded = list()\n",
        "\n",
        "for i in range(train_y.shape[1]):\n",
        "    c=train_y[:,i][0]\n",
        "    letter = [0 for _ in range(no_of_class)]\n",
        "    letter[c] = 1\n",
        "    onehot_encoded.append(letter)\n",
        "\n",
        "N=np.array(onehot_encoded)\n",
        "Y=N.reshape(no_of_class,train_y.shape[1])\n",
        "for i in range(0,train_y.shape[1]):\n",
        "      Y[:,i] = N[i]\n",
        "\n",
        "onehot_encoded_y_val = list()\n",
        "\n",
        "for i in range(y_val.shape[1]):\n",
        "    c=y_val[:,i][0]\n",
        "    letter = [0 for _ in range(no_of_class)]\n",
        "    letter[c] = 1\n",
        "    onehot_encoded_y_val.append(letter)\n",
        "\n",
        "\n",
        "M=np.array(onehot_encoded_y_val)\n",
        "Y_val=M.reshape(no_of_class,y_val.shape[1])\n",
        "for i in range(0,y_val.shape[1]):\n",
        "      Y_val[:,i] = N[i]\n",
        "\n",
        "\n",
        "layers_dims = [len(train_x),256,128,no_of_class]\n",
        "\n",
        "\n",
        "def initialize_parameters(layers_dims,initialization):    \n",
        "    np.random.seed(3)\n",
        "    parameters = {}\n",
        "    L = len(layers_dims)            # number of layers in the network\n",
        "\n",
        "    for l in range(1, L):\n",
        "        if initialization == 'Normal':\n",
        "            parameters[\"W\"+str(l)] = np.random.randn(layers_dims[l], layers_dims[l-1]) * 0.01\n",
        "        elif initialization == 'Uniform':\n",
        "            parameters[\"W\"+str(l)] = np.random.rand(layers_dims[l], layers_dims[l-1]) * 0.01\n",
        "        elif initialization == 'Xavier':\n",
        "            parameters[\"W\"+str(l)]= np.random.randn(layers_dims[l],layers_dims[l-1])*np.sqrt(2/(layers_dims[l]+layers_dims[l-1]))\n",
        "        parameters['b' + str(l)] =  np.zeros((layers_dims[l], 1))\n",
        "    return parameters\n",
        "\n",
        "def prev_updates(layers_dims):\n",
        "        previous_updates = {}\n",
        "        L = len(layers_dims)            # number of layers in the network\n",
        "        for l in range(1, L):\n",
        "            previous_updates[\"W\"+str(l)] = np.zeros((layers_dims[l], layers_dims[l-1]))\n",
        "            previous_updates[\"b\"+str(l)] = np.zeros((layers_dims[l], 1))\n",
        "                    \n",
        "        return previous_updates\n",
        "\n",
        "\n",
        "def feed_forward(A, W, b):\n",
        "\n",
        "    Z =np.dot(W, A) + b\n",
        "    cache = (A, W, b)\n",
        "    \n",
        "    return Z, cache \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def sigmoid(Z):\n",
        "    A = 1/(1+np.exp(-Z))\n",
        "    cache = Z\n",
        "    return A, cache\n",
        "\n",
        "def relu(Z):\n",
        "    \n",
        "    A = np.maximum(0,Z)\n",
        "    \n",
        "    assert(A.shape == Z.shape)\n",
        "    \n",
        "    cache = Z \n",
        "    return A, cache\n",
        "\n",
        "def Relu_derivative(Z):\n",
        "    return 1*(Z>0) \n",
        "\n",
        "def tanh(Z):\n",
        "    return np.tanh(Z)\n",
        "\n",
        "def tanh_backward(Z):\n",
        "    t = np.tanh(Z)\n",
        "    dt = 1 - (t**2)\n",
        "    return dt\n",
        "\n",
        "def sigmoid_backward(dA, cache):\n",
        "   \n",
        "    Z = cache\n",
        "    s = 1/(1+np.exp(-Z))\n",
        "    dZ = dA * s * (1-s)\n",
        "    \n",
        "    return dZ\n",
        "\n",
        "def relu_backward(dA, cache):\n",
        "\n",
        "    \n",
        "    Z = cache\n",
        "    dZ = np.array(dA, copy=True) \n",
        "    \n",
        "    dZ[Z <= 0] = 0\n",
        "    \n",
        "    assert (dZ.shape == Z.shape)\n",
        "    \n",
        "    return dZ\n",
        "    \n",
        "\n",
        " \n",
        "def softmax(n):\n",
        " \te = exp(n)\n",
        " \treturn e / e.sum()\n",
        " \t\n",
        " \t\n",
        " \t\n",
        "def activation_forward(A_prev, W, b, activation):\n",
        "    if activation == \"sigmoid\":\n",
        "        Z, linear_cache  = feed_forward(A_prev, W, b)\n",
        "        A, activation_cache = sigmoid(Z)\n",
        "\n",
        "    if activation == \"tanh\":\n",
        "        Z, linear_cache  = feed_forward(A_prev, W, b)\n",
        "        A, activation_cache = tanh(Z)\n",
        "    \n",
        "    if activation == \"relu\":\n",
        "        \n",
        "        Z, linear_cache = feed_forward(A_prev, W, b)\n",
        "        A, activation_cache = relu(Z)\n",
        "\n",
        "    cache = (linear_cache, activation_cache)\n",
        "\n",
        "    return A, cache\n",
        "\n",
        "\n",
        "def L_model_forward(X, parameters):\n",
        "    \n",
        "    caches = []\n",
        "    A = X\n",
        "    L = len(parameters) // 2                  # number of layers in the neural network\n",
        "    \n",
        "    for l in range(1, L):\n",
        "        A_prev = A \n",
        "        A, cache = activation_forward(A_prev, parameters['W' + str(l)], parameters['b' + str(l)], activation)\n",
        "        caches.append(cache)\n",
        "        \n",
        "    AL, cache = activation_forward(A, parameters['W' + str(L)], parameters['b' + str(L)], activation)\n",
        "    caches.append(cache)\n",
        "            \n",
        "    return AL, caches\n",
        "    \n",
        "#backpropagtion    \n",
        "def linear_backward(dZ, cache):\n",
        "    A_prev, W, b = cache\n",
        "    m = A_prev.shape[1]\n",
        "    dW = 1./m*np.dot(dZ, A_prev.T)\n",
        "    db = 1./m*np.sum(dZ, axis = 1, keepdims=True)\n",
        "    dA_prev = np.dot(W.T, dZ)\n",
        "    return dA_prev, dW, db\n",
        "\n",
        "    \n",
        "    \n",
        "def activation_backward(dA, cache, activation):\n",
        "    linear_cache, activation_cache = cache\n",
        "    \n",
        "    if activation == \"relu\":\n",
        "        dZ = relu_backward(dA, activation_cache)\n",
        "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
        "    \n",
        "    if activation == \"tanh\":\n",
        "        dZ = tanh_backward(dA, activation_cache)\n",
        "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
        "\n",
        "        \n",
        "    if activation == \"sigmoid\":\n",
        "        dZ = sigmoid_backward(dA, activation_cache)\n",
        "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
        "\n",
        "    \n",
        "    return dA_prev, dW, db    \n",
        "\n",
        "def L_model_backward(Y,AL, caches):\n",
        "    grads = {}\n",
        "    L = len(caches) # the number of layers\n",
        "    m = AL.shape[1]\n",
        "    Y = Y.reshape(AL.shape) \n",
        "    # Initializing the backpropagation\n",
        "    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
        "    \n",
        "    current_cache = caches[L-1]\n",
        "    grads[\"dA\" + str(L)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = activation_backward(dAL, current_cache, activation)\n",
        "    \n",
        "    for l in reversed(range(L-1)):\n",
        "        current_cache = caches[l]\n",
        "        dA_prev_temp, dW_temp, db_temp = activation_backward(grads[\"dA\" + str(l + 2)],  current_cache, activation)\n",
        "        grads[\"dA\" + str(l + 1)] = dA_prev_temp\n",
        "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
        "        grads[\"db\" + str(l + 1)] = db_temp\n",
        "\n",
        "    return grads\n",
        "def update_parameters(parameters, grads, learning_rate,lamda):\n",
        "    \n",
        "    L = len(parameters) // 2 # number of layers in the neural network\n",
        "\n",
        "    for l in range(L):\n",
        "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate * grads[\"dW\" + str(l + 1)] \n",
        "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate * grads[\"db\" + str(l + 1)]\n",
        "        \n",
        "    return parameters\n",
        "    \n",
        "#stochastic gradient    \n",
        "\n",
        "\n",
        "def stochastic_gradient(X, Y, layers_dims, learning_rate,num_epochs,lamda,initialisation):\n",
        "          parameters = initialize_parameters(layers_dims,initialisation)\n",
        "          for j in range(0,num_epochs):\n",
        "            for i in range(0,iterations_bat):\n",
        "                start = i*batch_size\n",
        "                end = start+batch_size\n",
        "                AL, caches = L_model_forward(X[:,start:end], parameters)\n",
        "                grads = L_model_backward(Y[:,start:end],AL, caches)\n",
        "                parameters = update_parameters(parameters, grads, learning_rate,lamda)\n",
        "            z_pred_1, caches = L_model_forward(train_x, parameters)\n",
        "            z_pred = np.argmax(z_pred_1,axis = 0)\n",
        "            zyy = train_y.flatten()\n",
        "            z_acc = accuracy_score(zyy,z_pred)\n",
        "            print(\"Train accuracy\",z_acc) \n",
        "            val_pred, caches = L_model_forward(x_val, parameters)\n",
        "            val_prediction = np.argmax(val_pred,axis = 0)\n",
        "            val_y_flat = y_val.flatten()\n",
        "            val_acc = accuracy_score(val_y_flat,val_prediction)\n",
        "            print(\"validation accuracy\",val_acc) \n",
        "          return parameters.z_acc,val_acc\n",
        "#momentum gradient descent optimizer\n",
        "def momentum(X,Y,layers_dims,learning_rate,beta,num_epochs,initialisation):\n",
        "    parameters = initialize_parameters(layers_dims,initialisation)\n",
        "    previous_updates =prev_updates(layers_dims)\n",
        "    L = len(parameters) // 2 # number of layers in the neural network\n",
        "    for j in range(0,num_epochs):\n",
        "        for i in range(0,iterations_bat):\n",
        "            start = i*batch_size\n",
        "            end = start+batch_size\n",
        "            AL, caches = L_model_forward(X[:,start:end], parameters)\n",
        "            grads = L_model_backward(Y[:,start:end],AL, caches)\n",
        "                                   \n",
        "            for l in range(1, L + 1):\n",
        "                previous_updates[\"W\"+str(l)] = (beta*previous_updates[\"W\"+str(l)]) + ((1-beta)*grads[\"dW\" + str(l)])\n",
        "                parameters[\"W\" + str(l)] = parameters[\"W\" + str(l)] - (learning_rate*previous_updates[\"W\"+str(l)])\n",
        "                \n",
        "                previous_updates[\"b\"+str(l)] = (beta*previous_updates[\"b\"+str(l)]) + ((1-beta)*grads[\"db\" + str(l)])\n",
        "                parameters[\"b\" + str(l)] = parameters[\"b\" + str(l)] - (learning_rate*previous_updates[\"b\"+str(l)])\n",
        "            \n",
        "          \n",
        "        z_pred_1, caches = L_model_forward(train_x, parameters)\n",
        "        z_pred = np.argmax(z_pred_1,axis = 0)\n",
        "        zyy = train_y.flatten()\n",
        "        z_acc = accuracy_score(zyy,z_pred)\n",
        "        print(\"Train accuracy\",z_acc) \n",
        "        val_pred, caches = L_model_forward(x_val, parameters)\n",
        "        val_prediction = np.argmax(val_pred,axis = 0)\n",
        "        val_y_flat = y_val.flatten()\n",
        "        val_acc = accuracy_score(val_y_flat,val_prediction)\n",
        "        print(\"validation accuracy\",val_acc) \n",
        "\n",
        "    return parameters, previous_updates,z_acc,val_acc\n",
        "# rmsprop optimizer\n",
        "def rmsprop(X,Y,layers_dims,learning_rate,beta,num_epochs,initialisation):\n",
        "    parameters = initialize_parameters(layers_dims,initialisation)\n",
        "    previous_updates =prev_updates(layers_dims)\n",
        "    for j in range(0,num_epochs):\n",
        "        for i in range(0,iterations_bat):\n",
        "           \n",
        "           start = i*batch_size\n",
        "           end = start+batch_size\n",
        "           AL, caches = L_model_forward(X[:,start:end], parameters)\n",
        "\n",
        "           grads = L_model_backward(AL, Y[:,start:end], caches)\n",
        "\n",
        "           delta = 1e-6 \n",
        "            \n",
        "           L = len(parameters) // 2 \n",
        "        \n",
        "           for l in range(1, L + 1):\n",
        "                vdw = beta*previous_updates[\"W\" + str(l)] + (1-beta)*np.multiply(grads[\"dW\" + str(l)],grads[\"dW\" + str(l)])\n",
        "                vdb = beta*previous_updates[\"b\" + str(l)] + (1-beta)*np.multiply(grads[\"db\" + str(l)],grads[\"db\" + str(l)])\n",
        "        \n",
        "                parameters[\"W\" + str(l)] = parameters[\"W\" + str(l)] - learning_rate * grads[\"dW\" + str(l)] / (np.sqrt(vdw)+delta)\n",
        "                parameters[\"b\" + str(l)] = parameters[\"b\" + str(l)] - learning_rate * grads[\"db\" + str(l)] / (np.sqrt(vdb)+delta)\n",
        "        \n",
        "                previous_updates[\"W\" + str(l)] = vdw\n",
        "                previous_updates[\"b\" + str(l)] = vdb\n",
        "           \n",
        "        z_pred_1, caches = L_model_forward(train_x, parameters)\n",
        "        z_pred = np.argmax(z_pred_1,axis = 0)\n",
        "        zyy = train_y.flatten()\n",
        "        z_acc = accuracy_score(zyy,z_pred)\n",
        "        print(\"Train accuracy\",z_acc) \n",
        "        val_pred, caches = L_model_forward(x_val, parameters)\n",
        "        val_prediction = np.argmax(val_pred,axis = 0)\n",
        "        val_y_flat = y_val.flatten()\n",
        "        val_acc = accuracy_score(val_y_flat,val_prediction)\n",
        "        print(\"validation accuracy\",val_acc) \n",
        "\n",
        "    return parameters, previous_updates,z_acc,val_acc\n",
        "\n",
        "def adam(X,Y,layers_dims,v,m,t,learning_rate,beta,num_epochs,initialisation):\n",
        "    parameters = initialize_parameters(layers_dims,initialisation)\n",
        "    for j in range(0,num_epochs):\n",
        "            for i in range(0,iterations_bat):\n",
        "                start = i*batch_size\n",
        "                end = start+batch_size\n",
        "                AL, caches = L_model_forward(X[:,start:end], parameters)\n",
        "                grads = L_model_backward(Y[:,start:end],AL, caches)\n",
        "                \n",
        "                L = len(parameters) // 2 # number of layers in the neural network\n",
        "                beta1 = 0.9\n",
        "                beta2 = 0.999\n",
        "                epsilon = 1e-8\n",
        "            \n",
        "                for l in range(1, L+1):\n",
        "                    mdw = beta1*m[\"W\"+str(l)] + (1-beta1)*grads[\"dW\"+str(l)]\n",
        "                    vdw = beta2*v[\"W\"+str(l)] + (1-beta2)*np.square(grads[\"dW\"+str(l)])\n",
        "                    mw_hat = mdw/(1.0 - beta1**t)\n",
        "                    vw_hat = vdw/(1.0 - beta2**t)\n",
        "            \n",
        "                    parameters[\"W\"+str(l)] = parameters[\"W\"+str(l)] - (learning_rate * mw_hat)/np.sqrt(vw_hat + epsilon)\n",
        "            \n",
        "                    mdb = beta1*m[\"b\"+str(l)] + (1-beta1)*grads[\"db\"+str(l)]\n",
        "                    vdb = beta2*v[\"b\"+str(l)] + (1-beta2)*np.square(grads[\"db\"+str(l)])\n",
        "                    mb_hat = mdb/(1.0 - beta1**t)\n",
        "                    vb_hat = vdb/(1.0 - beta2**t)\n",
        "            \n",
        "                    parameters[\"b\"+str(l)] = parameters[\"b\"+str(l)] - (learning_rate * mb_hat)/np.sqrt(vb_hat + epsilon)\n",
        "            \n",
        "                    v[\"dW\"+str(l)] = vdw\n",
        "                    m[\"dW\"+str(l)] = mdw\n",
        "                    v[\"db\"+str(l)] = vdb\n",
        "                    m[\"db\"+str(l)] = mdb\n",
        "            \n",
        "                t = t + 1 # timestep   \n",
        "            \n",
        "            z_pred_1, caches = L_model_forward(train_x, parameters)\n",
        "            z_pred = np.argmax(z_pred_1,axis = 0)\n",
        "            zyy = train_y.flatten()\n",
        "            z_acc = accuracy_score(zyy,z_pred)\n",
        "            print(\"Train accuracy\",z_acc) \n",
        "            val_pred, caches = L_model_forward(x_val, parameters)\n",
        "            val_prediction = np.argmax(val_pred,axis = 0)\n",
        "            val_y_flat = y_val.flatten()\n",
        "            val_acc = accuracy_score(val_y_flat,val_prediction)\n",
        "            print(\"validation accuracy\",val_acc) \n",
        "\n",
        "    return parameters,v,m,t,z_acc,val_acc\n",
        "\n",
        "def Nadam(X,Y,layers_dims,m,v,t,learning_rate,beta,num_epochs,initialisation):\n",
        "    parameters = initialize_parameters(layers_dims,initialisation)\n",
        "    previous_updates = v\n",
        "    L = len(parameters )//2\n",
        "    for j in range(0,num_epochs):\n",
        "        for l in range(1, L+1):\n",
        "            parameters [\"W\"+str(l)] = parameters [\"W\"+str(l)] - beta*previous_updates[\"W\"+str(l)]\n",
        "            parameters [\"b\"+str(l)] = parameters [\"b\"+str(l)] - beta*previous_updates[\"b\"+str(l)]\n",
        "        for i in range(0,iterations_bat):\n",
        "            start = i*batch_size\n",
        "            end = start+batch_size\n",
        "            AL, caches = L_model_forward(X[:,start:end], parameters)\n",
        "            grads = L_model_backward( Y[:,start:end],AL,caches)\n",
        "            \n",
        "            L = len(parameters) // 2 # number of layers in the neural network\n",
        "            beta1 = 0.9\n",
        "            beta2 = 0.999\n",
        "            epsilon = 1e-8\n",
        "        \n",
        "            for l in range(1, L+1):\n",
        "                mdw = beta1*m[\"W\"+str(l)] + (1-beta1)*grads[\"dW\"+str(l)]\n",
        "                vdw = beta2*v[\"W\"+str(l)] + (1-beta2)*np.square(grads[\"dW\"+str(l)])\n",
        "                mw_hat = mdw/(1.0 - beta1**t)\n",
        "                vw_hat = vdw/(1.0 - beta2**t)\n",
        "        \n",
        "                parameters[\"W\"+str(l)] = parameters[\"W\"+str(l)] - (learning_rate * mw_hat)/np.sqrt(vw_hat + epsilon)\n",
        "        \n",
        "                mdb = beta1*m[\"b\"+str(l)] + (1-beta1)*grads[\"db\"+str(l)]\n",
        "                vdb = beta2*v[\"b\"+str(l)] + (1-beta2)*np.square(grads[\"db\"+str(l)])\n",
        "                mb_hat = mdb/(1.0 - beta1**t)\n",
        "                vb_hat = vdb/(1.0 - beta2**t)\n",
        "        \n",
        "                parameters[\"b\"+str(l)] = parameters[\"b\"+str(l)] - (learning_rate * mb_hat)/np.sqrt(vb_hat + epsilon)\n",
        "        \n",
        "                v[\"dW\"+str(l)] = vdw\n",
        "                m[\"dW\"+str(l)] = mdw\n",
        "                v[\"db\"+str(l)] = vdb\n",
        "                m[\"db\"+str(l)] = mdb\n",
        "        \n",
        "            t = t + 1 # timestep            \n",
        "\n",
        "        z_pred_1, caches = L_model_forward(train_x, parameters)\n",
        "        z_pred = np.argmax(z_pred_1,axis = 0)\n",
        "        zyy = train_y.flatten()\n",
        "        z_acc = accuracy_score(zyy,z_pred)\n",
        "        print(\"Train accuracy\",z_acc) \n",
        "        val_pred, caches = L_model_forward(x_val, parameters)\n",
        "        val_prediction = np.argmax(val_pred,axis = 0)\n",
        "        val_y_flat = y_val.flatten()\n",
        "        val_acc = accuracy_score(val_y_flat,val_prediction)\n",
        "        print(\"validation accuracy\",val_acc) \n",
        "\n",
        "    return parameters,z_acc,val_acc\n",
        "\n",
        "def nesterov(X,Y,learning_rate,beta,previous_updates,num_epochs,initialisation):\n",
        "        \n",
        "    parameters=initialize_parameters(layers_dims,initialisation)\n",
        "    L = len(parameters)//2\n",
        "    for j in range(0,num_epochs):\n",
        "        for l in range(1, L+1):\n",
        "            parameters[\"W\"+str(l)] = parameters[\"W\"+str(l)] - beta*previous_updates[\"W\"+str(l)]\n",
        "            parameters[\"b\"+str(l)] = parameters[\"b\"+str(l)] - beta*previous_updates[\"b\"+str(l)]\n",
        "        for i in range(0,iterations_bat):\n",
        "            start = i*batch_size\n",
        "            end = start+batch_size    \n",
        "            AL, caches = L_model_forward(X[:,start:end], parameters)\n",
        "            grads = L_model_backward( Y[:,start:end],AL,caches)\n",
        "            \n",
        "            L = len(parameters) // 2 # number of layers in the neural network\n",
        "           \n",
        "            for l in range(1, L + 1):\n",
        "                previous_updates[\"W\"+str(l)] = beta*previous_updates[\"W\"+str(l)] + (1-beta)*grads[\"dW\" + str(l)]\n",
        "                parameters[\"W\" + str(l)] = parameters[\"W\" + str(l)] - learning_rate*previous_updates[\"W\"+str(l)]\n",
        "                \n",
        "                previous_updates[\"b\"+str(l)] = beta*previous_updates[\"b\"+str(l)] + (1-beta)*grads[\"db\" + str(l)]\n",
        "                parameters[\"b\" + str(l)] = parameters[\"b\" + str(l)] - learning_rate*previous_updates[\"b\"+str(l)]\n",
        "             \n",
        "        z_pred_1, caches = L_model_forward(train_x, parameters)\n",
        "        z_pred = np.argmax(z_pred_1,axis = 0)\n",
        "        zyy = train_y.flatten()\n",
        "        z_acc = accuracy_score(zyy,z_pred)\n",
        "        print(\"Train accuracy\",z_acc) \n",
        "        val_pred, caches = L_model_forward(x_val, parameters)\n",
        "        val_prediction = np.argmax(val_pred,axis = 0)\n",
        "        val_y_flat = y_val.flatten()\n",
        "        val_acc = accuracy_score(val_y_flat,val_prediction)\n",
        "        print(\"validation accuracy\",val_acc) \n",
        "\n",
        "    return parameters,z_acc,val_acc            \n",
        "\n",
        "\n",
        "def MSE(X,Y,parameters):\n",
        "    AL, caches = L_model_forward(X, parameters)\n",
        "    sm=[]\n",
        "    for i in range(AL.shape[1]):\n",
        "        n=AL[:,i]\n",
        "        u=softmax(n)\n",
        "        sm.append(u)\n",
        "    p=np.array(sm) \n",
        "    v=p.T\n",
        "    Loss = (1/2) * np.sum((Y-v)**2)/train_x.shape[1]\n",
        "    return Loss\n",
        "\n",
        "\n",
        "def cross_entropy_loss(X,Y,parameters):\n",
        "    AL, caches = L_model_forward(X, parameters)\n",
        "    sm=[]\n",
        "    for i in range(AL.shape[1]):\n",
        "        n=AL[:,i]\n",
        "        u=softmax(n)\n",
        "        sm.append(u)\n",
        "    p=np.array(sm) \n",
        "    v=p.T\n",
        "    val=-np.sum(Y*(np.log(v)))\n",
        "    val=val/train_x.shape[1]    \n",
        "    return val\n",
        "    \n",
        "global batch_size\n",
        "global iterations_bat\n",
        "global activation\n",
        "    "
      ],
      "metadata": {
        "id": "3pIuC5dTXotf"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_netwrok(learning_rate,num_epochs,optimizer,loss,init_param,hid_layer_sizes,bat_size,activate_func):\n",
        "    t = 1\n",
        "    beta = 0.9\n",
        "    lamda = 0.0005\n",
        "    hid_layer_sizes\n",
        "    no_of_class = [len(np.unique(train_y))]\n",
        "    layers_dims = [len(train_x)] + hid_layer_sizes +no_of_class\n",
        "    global activation\n",
        "    global batch_size\n",
        "    global iterations_bat\n",
        "    activation = activate_func\n",
        "    batch_size = bat_size\n",
        "    iterations_bat = int(train_x.shape[1]/batch_size) \n",
        "\n",
        "    print(layers_dims)\n",
        "#    loss = \"cross_entropy\"\n",
        "    initialisation = init_param #\"Xavier\"\n",
        "    gd_optimizer = optimizer\n",
        "    previous_updates = prev_updates(layers_dims)\n",
        "    if(gd_optimizer == \"stochastic_gradient\"):\n",
        "        parameters,z_acc,val_acc =stochastic_gradient(train_x, Y, layers_dims, learning_rate,num_epochs,lamda,initialisation)\n",
        "        if loss ==\"cross_entropy\" :\n",
        "            Train_loss = cross_entropy_loss(train_x,Y,parameters)\n",
        "            Val_loss = cross_entropy_loss(x_val,Y_val,parameters)\n",
        "            print(Train_loss)\n",
        "            print(Val_loss)\n",
        "        elif loss ==\"MSE\" :\n",
        "             Train_loss = MSE(train_x,Y,parameters) \n",
        "             Val_loss = cross_entropy_loss(x_val,Y_val,parameters)\n",
        "             print(Train_loss)\n",
        "             print(Val_loss)\n",
        "    if(gd_optimizer == \"momentum\"):\n",
        "        parameters,previous_updates,z_acc,val_acc=momentum(train_x,Y,layers_dims,learning_rate,beta,num_epochs,initialisation)\n",
        "        if loss == \"cross_entropy\" :\n",
        "            Train_loss = cross_entropy_loss(train_x,Y,parameters)\n",
        "            Val_loss = cross_entropy_loss(x_val,Y_val,parameters)\n",
        "            print(Train_loss)\n",
        "            print(Val_loss)\n",
        "        elif loss == \"MSE\" :\n",
        "             Train_loss = MSE(train_x,Y,parameters) \n",
        "             Val_loss = cross_entropy_loss(x_val,Y_val,parameters)\n",
        "             print(Train_loss)\n",
        "             print(Val_loss)\n",
        "    if(gd_optimizer == \"rmsprop\"):\n",
        "        parameters, previous_updates,z_acc,val_acc=rmsprop(train_x,Y,layers_dims,learning_rate,beta,num_epochs,initialisation)\n",
        "        if loss == \"cross_entropy\" :\n",
        "            Train_loss = cross_entropy_loss(train_x,Y,parameters)\n",
        "            Val_loss = cross_entropy_loss(x_val,Y_val,parameters)\n",
        "            print(Train_loss)\n",
        "            print(Val_loss)\n",
        "        elif loss == \"MSE\" :\n",
        "             Train_loss = MSE(train_x,Y,parameters)\n",
        "             Val_loss = cross_entropy_loss(x_val,Y_val,parameters)\n",
        "             print(Train_loss)\n",
        "             print(Val_loss)\n",
        "    if(gd_optimizer == \"Adam\"):\n",
        "        parameters,v,m,t,z_acc,val_acc=adam(train_x,Y,layers_dims,previous_updates,previous_updates,t,learning_rate,beta,num_epochs,initialisation)\n",
        "        if loss == \"cross_entropy\" :\n",
        "            Train_loss = cross_entropy_loss(train_x,Y,parameters)\n",
        "            Val_loss = cross_entropy_loss(x_val,Y_val,parameters)\n",
        "            print(Train_loss)\n",
        "            print(Val_loss)\n",
        "        elif loss == \"MSE\" :\n",
        "             Train_loss = MSE(train_x,Y,parameters) \n",
        "             Val_loss = cross_entropy_loss(x_val,Y_val,parameters)\n",
        "             print(Train_loss)\n",
        "             print(Val_loss)\n",
        "    if(gd_optimizer == \"Nadam\"): \n",
        "        parameters,z_acc,val_acc=Nadam(train_x,Y,layers_dims,previous_updates,previous_updates,t,learning_rate,beta,num_epochs,initialisation)\n",
        "        if loss == \"cross_entropy\" :\n",
        "            Train_loss = cross_entropy_loss(train_x,Y,parameters)\n",
        "            Val_loss = cross_entropy_loss(x_val,Y_val,parameters)\n",
        "            print(Train_loss)\n",
        "            print(Val_loss)\n",
        "        elif loss == \"MSE\" :\n",
        "             Train_loss = MSE(train_x,Y,parameters)\n",
        "             Val_loss = cross_entropy_loss(x_val,Y_val,parameters)\n",
        "             print(Train_loss)\n",
        "             print(Val_loss)\n",
        "    if(gd_optimizer == \"nesterov\"):\n",
        "        parameters,z_acc,val_acc=nesterov(train_x,Y,learning_rate,beta,previous_updates,num_epochs,initialisation)\n",
        "        if loss == \"cross_entropy\" :\n",
        "            Train_loss = cross_entropy_loss(train_x,Y,parameters)\n",
        "            Val_loss = cross_entropy_loss(x_val,y_val,parameters)\n",
        "            print(Train_loss)\n",
        "            print(Val_loss)\n",
        "        elif loss == \"MSE\" :\n",
        "             Train_loss = MSE(train_x,Y,parameters)  \n",
        "             Val_loss = cross_entropy_loss(x_val,Y_val,parameters)\n",
        "             print(Train_loss)\n",
        "             print(Val_loss)\n",
        "    train_accuracy = z_acc * 100\n",
        "    val_accuracy = val_acc * 100\n",
        "    wandb.log({'train_loss':Train_loss})         \n",
        "    wandb.log({'train_accuracy':train_accuracy})\n",
        "    wandb.log({'val_accuracy':val_accuracy})\n",
        "    wandb.log({'val_loss':Val_loss})\n",
        "    wandb.log({'num_epochs':num_epochs})\n",
        "\n",
        "    return val_accuracy        \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 798
        },
        "id": "Jitq8AAXTSqI",
        "outputId": "f19d10a6-f054-432d-d8ce-7ed86554da45"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f6a8c458550>> (for pre_run_cell):\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36m_resume_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"resuming backend\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_jupyter_teardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mpublish_resume\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpublish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0mresume\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResumeRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/interface/interface_shared.py\u001b[0m in \u001b[0;36m_publish_resume\u001b[0;34m(self, resume)\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResumeRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRunRecord\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/interface/interface_queue.py\u001b[0m in \u001b[0;36m_publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pb.Record\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_check\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The wandb backend process has shutdown\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: The wandb backend process has shutdown"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f6a8c458550>> (for post_run_cell):\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36m_pause_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    302\u001b[0m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"saved code: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_resume_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mpublish_pause\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    540\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpublish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0mpause\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauseRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/interface/interface_shared.py\u001b[0m in \u001b[0;36m_publish_pause\u001b[0;34m(self, pause)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpause\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauseRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResumeRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/interface/interface_queue.py\u001b[0m in \u001b[0;36m_publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pb.Record\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_check\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The wandb backend process has shutdown\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: The wandb backend process has shutdown"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_config = {\n",
        "    'method': 'random',\n",
        "    'metric': {\n",
        "      'name': 'validation_accuracy',\n",
        "      'goal': 'maximize' \n",
        "    },\n",
        "    'parameters': {\n",
        "        'learning_rate': {\n",
        "            'values': [0.01,0.001]\n",
        "        },\n",
        "        'num_epoch': {\n",
        "            'values': [10,15,20,30]\n",
        "        },\n",
        "        'optimizer': {\n",
        "            'values': ['Adam','Nadam','momentum','stochastic_gradient','rmsprop','nesterov']\n",
        "        },\n",
        "        'loss': {\n",
        "            'values': ['cross_entropy','MSE']\n",
        "        },\n",
        "        'init_param': {\n",
        "            'values': ['Xavier','Normal','Uniform']\n",
        "        },\n",
        "        'hid_layer_sizes': {\n",
        "            'values': [[256,128,64], [128,64,32],[128,128,128][64,64,64]]\n",
        "        }, \n",
        "        'bat_size': {\n",
        "            'values': [25,50,100]\n",
        "        }, \n",
        "        'activate_func': {\n",
        "            'values': ['sigmoid','relu','tanh']\n",
        "        }, \n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "T67Rlu8caU3j"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_id = wandb.sweep(sweep_config, project=\"Assignment-1\", entity=\"swe-rana\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZVwiEv5ZeJA",
        "outputId": "8172eba9-05fc-46e8-adc2-5a88aeef378f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: tkun9brv\n",
            "Sweep URL: https://wandb.ai/swe-rana/Assignment-1/sweeps/tkun9brv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "    config_defaults = {\n",
        "        'learning_rate': 0.01,\n",
        "        'num_epochs': 5,\n",
        "        'optimizer': 'Adam',\n",
        "        'loss': 'cross_entropy',\n",
        "        'init_param': 'Xavier',\n",
        "        'hid_layer_sizes' : [256,128],\n",
        "        'bat_size':50,\n",
        "        'activate_func': 'sigmoid'\n",
        "    }\n",
        "\n",
        "    wandb.init(config=config_defaults)\n",
        "    config = wandb.config\n",
        "    learning_rate = config.learning_rate\n",
        "    num_epochs = config.num_epochs\n",
        "    optimizer = config.optimizer\n",
        "    loss = config.loss\n",
        "    init_param = config.init_param\n",
        "    hid_layer_sizes = config.hid_layer_sizes\n",
        "    bat_size = config.bat_size\n",
        "    activate_func = config.activate_func\n",
        "    run_name = \"lr_{}_ac_{}_in_{}_op_{}_bs_{}_L2_{}_ep_{}_nn_{}_nh_{}\".format(learning_rate, activation_f, init_mode, optimizer, batch_size, L2_lamb, epochs, num_neurons, num_hidden)\n",
        "\n",
        "    accuracy=train_netwrok(learning_rate,num_epochs,optimizer,loss,init_param,hid_layer_sizes)\n",
        "    \n",
        "    wandb.run.name = run_name\n",
        "    wandb.run.save()\n",
        "    wandb.run.finish()\n"
      ],
      "metadata": {
        "id": "5gEZuC7jZ1TU"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning)\n",
        "wandb.agent(sweep_id, train, count=100)"
      ],
      "metadata": {
        "id": "YCwCQCW_bdmz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}